{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mounting Google Drive:\n",
        "The drive.mount('/content/drive') command mounts the user's Google Drive in the Colab environment."
      ],
      "metadata": {
        "id": "9O-fLtq5AWtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4lCfgHJm-ld",
        "outputId": "9aed0cae-836f-4a60-8d19-c623f8145a64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Preparation\n",
        "This code snippet focuses on preparing the dataset for further processing. It involves importing necessary libraries, defining the path to the directory containing images, listing images in the directory, checking the data type of the variable storing image names, and obtaining the total number of images in the dataset."
      ],
      "metadata": {
        "id": "Igzp9MijAbzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "path = '/content/drive/MyDrive/DS/benign'\n",
        "images=os.listdir(path)\n",
        "type(images)\n",
        "len(images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7tfA_gyHK-0",
        "outputId": "3f825d1e-79d1-44b1-9fb6-522ef7b2690a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Image Data Extraction:\n",
        "\n",
        "This code snippet iterates through a list of image file names within a designated directory. For each image file, it reads the image using OpenCV, converts it into a NumPy array, and appends the array to a list. The resulting list, img_data, contains all the image data from the directory."
      ],
      "metadata": {
        "id": "0Y760jgaBEx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_data=[]\n",
        "for img in images:\n",
        "    img_arr=cv2.imread(os.path.join(path,img))\n",
        "    img_data.append(img_arr)\n",
        ""
      ],
      "metadata": {
        "id": "5jueX2XXwSCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Visualization:\n",
        "\n",
        "This code snippet utilizes matplotlib to visualize the images stored in the img_data list. It generates a grid of subplots, each containing an image."
      ],
      "metadata": {
        "id": "4Bsa3ZKWBlUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,20))\n",
        "for i in range(len(img_data)):\n",
        "    plt.subplot(10,10,i+1)\n",
        "    plt.imshow(img_data[i])"
      ],
      "metadata": {
        "id": "THphxw0cwctf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Augmentation Configuration:\n",
        "\n",
        "This code sets up an image data generator using Keras' ImageDataGenerator class. Image augmentation parameters are passed to the constructor to specify the transformations to be applied to the images during training."
      ],
      "metadata": {
        "id": "Gj0uQrgbCDGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from skimage import io\n",
        "\n",
        "# Construct an instance of the ImageDataGenerator class\n",
        "# Pass the augmentation parameters through the constructor.\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=45,     #Random rotation between 0 and 45\n",
        "        width_shift_range=0.2,   #% shift\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='reflect')"
      ],
      "metadata": {
        "id": "xGizI1KRx3-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Image Augmentation Process:\n",
        "\n",
        "This code snippet performs image augmentation using the previously configured ImageDataGenerator. It generates augmented images on-the-fly and saves them to a specified directory. The code initializes a loop to generate augmented images."
      ],
      "metadata": {
        "id": "n9RTttDjCbcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "i = 0\n",
        "for batch in datagen.flow_from_directory(directory='/content/drive/MyDrive/DS', classes=[\"benign\"],\n",
        "                                         batch_size=16,\n",
        "                                         target_size=(1200, 1600),\n",
        "                                         color_mode=\"rgb\",\n",
        "                                         save_to_dir='/content/drive/MyDrive/TF2',\n",
        "                                         save_prefix=\"aug\",\n",
        "                                         save_format=\"png\"):\n",
        "    i += 1\n",
        "    if i > 24:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmk79hAiyNCs",
        "outputId": "c7ff39e7-7fe3-44e5-d81c-a349af2fac0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 16 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing split-folder with full functionalities"
      ],
      "metadata": {
        "id": "WjA9hllVCkgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install split-folders[full]"
      ],
      "metadata": {
        "id": "HupUTdyAa2Gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Splitting:\n",
        "The primary functionality of split-folders is to split a dataset into multiple subsets, typically train, validation, and test sets. It automatically divides the dataset into specified proportions and creates separate directories for each subset.\n",
        "\n",
        "# Splitting Process:\n",
        "\n",
        "The splitfolders.ratio() function processes the input dataset and splits it into the specified ratios for train, validation, and test sets.\n",
        "It creates directories within the specified output directory to store the split datasets, organizing them into train, validation, and test sets accordingly."
      ],
      "metadata": {
        "id": "A7-s2V21C5Ne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import splitfolders\n",
        "input_folder='/content/drive/MyDrive/hist_ben_dataset'\n",
        "splitfolders.ratio(input_folder, output=\"/content/drive/MyDrive/hist_ben_split\",\n",
        "                  seed=42, ratio=(.7,.2,.1),\n",
        "                  group_prefix=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xjwc5KIcN6q",
        "outputId": "388f8463-7dbf-4545-baa4-fb4827336eec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 3882 files [01:31, 42.23 files/s] \n"
          ]
        }
      ]
    }
  ]
}